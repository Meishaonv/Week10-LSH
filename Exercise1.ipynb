{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of articles:  10377\n",
      "Length of bag of words:  70793\n",
      "10377\n",
      "70793\n",
      "2068\n",
      "2076\n",
      "The accurary is: 99.61\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "articles = []\n",
    "weightArticles = []\n",
    "\n",
    "data_path = './data/'\n",
    "\n",
    "# Lets run through all the data json files\n",
    "for article_name in os.listdir(data_path):\n",
    "    # Load the JSON data from the file\n",
    "    data_file = open(data_path + article_name, 'r')   \n",
    "    data = json.load(data_file)\n",
    "    \n",
    "    # Run through each entry in every file and add the ones that have at least one topic and a body\n",
    "    for entry in data:\n",
    "        if (\"topics\" in entry and \"body\" in entry):\n",
    "            articles.append(entry[\"body\"])\n",
    "            # Creates a true or false array if it has the topic earn\n",
    "            if \"earn\" in entry[\"topics\"]:\n",
    "                weightArticles.append(True)\n",
    "            else:\n",
    "                weightArticles.append(False)\n",
    "                \n",
    "print \"Length of articles: \", len(articles)\n",
    "\n",
    "bag_of_word = set()\n",
    "# Creates a bag of words using set of all the different words in all the articles \n",
    "for article in articles:\n",
    "    temp_body = article \n",
    "    # Creates a set of different words as it makes it lowercase and splits the text after spaces\n",
    "    temp_list = set(temp_body.lower().split())\n",
    "    bag_of_word.update(temp_list)\n",
    "\n",
    "bag_of_word = list(bag_of_word)\n",
    "print \"Length of bag of words: \", len(bag_of_word)\n",
    "\n",
    "# Creates a dictionary bag of words filled with all the words and there index number in the bag of words list\n",
    "# bags_of_words_dict = { word1: 1, word2: 2, word3: 3}\n",
    "bags_of_words_dict = {}\n",
    "for i in range(0,len(bag_of_word)):\n",
    "    bags_of_words_dict[bag_of_word[i]] = i \n",
    "    \n",
    "vector_matrix = []\n",
    "\n",
    "for article in articles:\n",
    "    # Makes it lowercase and splits the text after spaces\n",
    "    article_word_array = article.lower().split()\n",
    "    # Creates an empty array of the bag of word size\n",
    "    empty = [0] * len(bag_of_word)\n",
    "             \n",
    "    for word in article_word_array:\n",
    "        indexOf = bags_of_words_dict[word] # Gets index of the word in big bag dictionary\n",
    "        empty[indexOf] += 1 # Fills the 0 list with the correct index with the right value\n",
    "\n",
    "    vector_matrix.append(empty)\n",
    "\n",
    "print len(vector_matrix)\n",
    "print len(vector_matrix[0])    \n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50) #use 50 trees(n_estimators) in classifier\n",
    "clf = clf.fit(vector_matrix[:8301],weightArticles[:8301]) #use 80% of data for training\n",
    "test_target = clf.predict(vector_matrix[8301:]) #use 20% of data for testing\n",
    "\n",
    "weight_results = weightArticles[8301:]\n",
    "# Compares the results of the test_target prediction to the right answers\n",
    "comp_result = [1 for i,j in zip(test_target, weight_results)if i==j]\n",
    "\n",
    "print (sum(comp_result))\n",
    "print len(weight_results)\n",
    "print 'The accurary is: %.2f' % (sum(comp_result)/float(len(weight_results))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10377\n",
      "2063\n",
      "2076\n",
      "The accurary is: 99.37\n"
     ]
    }
   ],
   "source": [
    "hash_list = []\n",
    "\n",
    "data_path = './data/'\n",
    "\n",
    "# Lets run through all the data json files\n",
    "for article_name in os.listdir(data_path):\n",
    "    # Load the JSON data from the file\n",
    "    data_file = open(data_path + article_name, 'r')   \n",
    "    data = json.load(data_file)\n",
    "    \n",
    "    # Run through each entry in every file and add the ones that have at least one topic and a body\n",
    "    for entry in data:\n",
    "        if (\"topics\" in entry and \"body\" in entry):\n",
    "            # Creates a array of size 1000 all with the value 0\n",
    "            empty = [0] * 1000\n",
    "            # Splits the words up by space and makes the word lowercase\n",
    "            words = entry[\"body\"].lower().split()\n",
    "            \n",
    "            for word in words:\n",
    "                # For each word we get a number between 0-1000 using the hash           \n",
    "                hashCode = hash(word) % 1000\n",
    "                # From the number we find the same index of the 0 array and add 1 to it\n",
    "                empty[hashCode] += 1\n",
    "            hash_list.append(empty)\n",
    "\n",
    "print len(hash_list)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50) # Use 50 trees(n_estimators) in classifier\n",
    "clf = clf.fit(hash_list[:8301],weightArticles[:8301]) # Use 80% of data for training\n",
    "test_target2 = clf.predict(hash_list[8301:]) # Use 20% of data for testing\n",
    "\n",
    "weight_results = weightArticles[8301:]\n",
    "# Compares the results of the test_target prediction to the right answers\n",
    "comp_result2 = [1 for i,j in zip(test_target2, weight_results)if i==j]\n",
    "\n",
    "print (sum(comp_result2))\n",
    "print len(weight_results)\n",
    "print 'The accurary is: %.2f' % (sum(comp_result2)/float(len(weight_results))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
